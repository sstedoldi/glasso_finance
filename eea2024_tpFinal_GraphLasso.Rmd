---
title: "Aplicación de Graphical LASSO en el Estudio de Valores del Mercado Financiero"
subtitle: "Enfoque Estadístico del Aprendizaje Automático - Data Mining UBA"
author: "Alumnos: Calderón Shirley y Tedoldi Santiago"
date: "10 de diciembre de 2024"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

<style type="text/css">
div.main-container {
  max-width: 1600px;
  margin-left: auto;
  margin-right: auto;
}
</style>

# Resumen

**Este trabajo propone una metodología innovadora para construir redes de dependencia entre acciones en el mercado financiero mediante el uso de Graphical LASSO (GLASSO). Al modelar las acciones como nodos de una red y analizar sus precios a lo largo del tiempo, buscamos identificar patrones de dependencias condicionales que podrían revelar tendencias y anomalías de interés para la toma de decisiones de inversión. La propuesta se centra en proporcionar una herramienta visual para comprender la estructura de dependencia en los activos financieros.**


# Carga de Librerías

```{r}
required.packages <- c('glasso', 'colorRamps', 'igraph', 'RColorBrewer', 'threejs', 'htmlwidgets','quantmod', 'tidyverse', 'PerformanceAnalytics')
new.packages <- required.packages[!(required.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, repos='http://cran.us.r-project.org')

library(ggplot2)
library(dplyr)
library(glasso);
library(colorRamps);
library(igraph);
library(RColorBrewer);
library(threejs);
library(htmlwidgets);
library(quantmod)
library(tidyverse)
library(PerformanceAnalytics)

```

# Valores bursátiles (stocks)

Se analizaran un total de 197 stocks, tomando los más conocidos a nivel internacional.

```{r}

symbols <- c("AAPL", "MSFT", "GOOG", "AMZN", "META", "TSLA", "BRK.A", "V", "JNJ", "WMT",
             "JPM", "MA", "PG", "UNH", "NVDA", "HD", "DIS", "PYPL", "VZ", "ADBE",
             "NFLX", "INTC", "CMCSA", "KO", "PFE", "PEP", "T", "MRK", "CSCO", "XOM",
             "ABT", "CVX", "NKE", "LLY", "ORCL", "MCD", "DHR", "COST", "WFC", "MDT",
             "ACN", "HON", "BMY", "AVGO", "TXN", "QCOM", "UNP", "NEE", "PM", "LIN",
             "AMGN", "LOW", "UPS", "MS", "IBM", "SBUX", "RTX", "GS", "BLK", "CAT",
             "SPGI", "PLD", "AMT", "TMO", "INTU", "CVS", "ISRG", "ELV", "GE", "LMT",
             "MDLZ", "BKNG", "DE", "ADP", "AXP", "SYK", "GILD", "ZTS", "CI", "CB",
             "MMC", "ADI", "MO", "SCHW", "USB", "C", "DUK", "SO", "TGT", "BDX",
             "PNC", "APD", "CL", "ITW", "NSC", "ICE", "CCI", "REGN", "EW", "SHW",
             "FIS", "TJX", "NOC", "ETN", "GM", "D", "ECL", "EMR", "MET", "ILMN",
             "AON", "WM", "PSA", "FISV", "HUM", "MCO", "ADSK", "AEP", "SRE", "SPG",
             "MCHP", "IDXX", "ROP", "KMB", "EXC", "ORLY", "TRV", "MSCI", "CTSH",
             "MAR", "AIG", "LRCX", "KLAC", "CDNS", "CTAS", "AZO", "CME", "APTV",
             "PRU", "WBA", "BIIB", "TEL", "EOG", "PPG", "STZ", "MPC", "ALL", "AFL",
             "ATVI", "DLR", "SYY", "BK", "A", "HPQ", "MNST", "WELL", "ROST", "YUM",
             "OXY", "PSX", "KHC", "DG", "HLT", "DHI", "MSI", "TT", "VLO", "GLW",
             "KEYS", "FTNT", "ODFL", "PAYX", "WMB", "CNC", "MTD", "PGR", "EBAY",
             "HCA", "CTVA", "LHX", "NEM", "FAST", "AMP", "KR", "VRSK", "WEC", "EQR",
             "PCAR", "DLTR", "SBAC", "TSN", "BAX", "DTE", "PEG", "ES", "ED", "FE")



length(symbols)
```
## Ventana temporal

La elección de la ventana de tiempo adecuada para el análisis de clustering de valores bursátiles y sus retornos depende de los objetivos específicos del análisis y de las características de los datos que deseas capturar. Aquí algunos enfoques para elegir una ventana de tiempo prudente:

1. **Ventana de 6 a 12 meses**:
   - **Objetivo**: Capturar tendencias y comportamiento reciente.
   - **Ventajas**: Captura el comportamiento en respuesta a eventos económicos recientes (por ejemplo, cambios en la política monetaria, crisis económicas). Permite agrupar acciones que están reaccionando de manera similar a situaciones actuales.
   - **Uso recomendado**: Esta ventana de tiempo es útil si tu objetivo es identificar patrones de comportamiento a corto plazo o si estás interesado en clasificar los stocks en función de cambios recientes del mercado.

2. **Ventana de 24 a 36 meses**:
   - **Objetivo**: Capturar patrones a mediano plazo.
   - **Ventajas**: Permite analizar el comportamiento de los valores a lo largo de un ciclo económico, teniendo en cuenta más eventos de mercado y distintas fases del ciclo. Es suficientemente larga como para evitar ruido temporal de corto plazo.
   - **Uso recomendado**: Útil para identificar clusters de acciones que mantienen características similares durante períodos más largos, lo cual puede ser indicativo de la estructura de sus industrias o estrategias subyacentes.

3. **Ventana de 3 a 5 años o más**:
   - **Objetivo**: Capturar la tendencia de largo plazo y los patrones de comportamiento cíclico.
   - **Ventajas**: Permite ver cómo los diferentes valores se comportan en situaciones diversas a largo plazo, incluyendo períodos de expansión y contracción del mercado.
   - **Uso recomendado**: Útil si estás buscando analizar características estructurales o fundamentales de los valores. A largo plazo, las agrupaciones obtenidas reflejarán similitudes en los fundamentos del negocio o la resistencia a factores de mercado, y no tanto el comportamiento a corto plazo.

4. **Ventana adaptativa (rolling window)**:
   - Otra estrategia podría ser utilizar una ventana de tiempo rodante, por ejemplo, de 12 meses que vaya moviéndose cada mes o trimestre. Esto te permitiría observar cómo evolucionan los clusters a lo largo del tiempo y cómo cambian los comportamientos de las acciones.
   - **Objetivo**: Identificar cambios en los patrones de comportamiento de los stocks a lo largo del tiempo.
   - **Ventajas**: Captura cómo se modifican los grupos durante distintas fases del mercado y permite estudiar transiciones de comportamiento.

Para evaluar estos valores en diferentes **condiciones de mercado** (por ejemplo, tanto en tiempos de expansión como de recesión), usaremos una ventana de **36 meses**.

```{r}

end_date <- Sys.Date() - days(1) # ayer
start_date <- end_date - months(36)

print(end_date)
print(start_date)

```

## Descarga de datos

Se define una función que utiliza la función getSymbols() pertenece al paquete **quantmod** y se utiliza para descargar datos financieros de diferentes fuentes (por defecto Yahoo Finance). Luego, la función Cl(), del mismo paquete, extrae los precios de cierre ajustado de un objeto tipo OHLCV (Open, High, Low, Close, Volume).

```{r}

get_stock_data <- function(symbol) {
  tryCatch({
    stock_data <- getSymbols(symbol, src = "yahoo", from = start_date, to = end_date, auto.assign = FALSE)
    stock_data <- Cl(stock_data)
    colnames(stock_data) <- symbol
    return(stock_data)
  }, error = function(e) {
    message(paste("No se pudieron obtener datos para", symbol))
    return(NULL)
  })
}

get_stock_sector <- function(symbol) {
  url <- paste0("https://finance.yahoo.com/quote/", symbol, "/profile?p=", symbol)
  webpage <- read_html(url)
  sector <- webpage %>%
    html_nodes(xpath = '//span[contains(text(), "Sector")]/following-sibling::span') %>%
    html_text()
  return(sector)
}

```

Se aplica la función creada para las stocks definidas previamente, aplicando un merge para combinar las series temporales de cada símbolo en un único xts (serie temporal extensible).

```{r}

stock_list <- lapply(symbols, get_stock_data)
stock_data <- do.call(merge, stock_list)

```

## Guardando datos localmente

Para evitar volver a consultar la API de yahoo finance:

```{r}

stock_data <- as.data.frame(stock_data)

stock_data$fecha <- rownames(stock_data)

write.table(stock_data, file = sprintf("yahoo_data_%s.txt", end_date), row.names = F, col.names = T)

```

## Lectura de los datos

Lectura de los datos guardados con fecha 2024-12-04, con 36 meses de valores: 

```{r}

# stock_data <- read.table(sprintf("yahoo_data_%s.txt", end_date), header = TRUE)
stock_data <- read.table("yahoo_data_2024-12-04.txt", header = TRUE)

# Convertir la columna 'fecha' a nombres de fila
rownames(stock_data) <- stock_data$fecha
stock_data$fecha <- NULL

# Mostrar el resultado
stock_data

```

## Preprocesamiento

Se descartan las columnas con datos faltantes o rotas. Luego, se preparan los dataframes para analizar los datos obtenidos de Internet.

Además, se calculan los retornos usando la función ROC que proviene del paquete TTR, el cual usualmente se instala de manera automática junto con quantmod, y sirve para calcular la tasa de cambio de una serie temporal de precios u otros datos financieros. Su uso típico es con precios de un activo en diferentes momentos y se emplea frecuentemente en análisis técnico para medir cuánto varía el precio entre un punto actual y un punto anterior.

```{r}

# Eliminar columnas con datos faltantes
# stock_data <- na.omit(stock_data) # quita muchas filas, por ausencias o falta de nombres

# Calcular retornos diarios
returns <- ROC(stock_data, type = "discrete")

# Convertir a tibble y agregar columnas útiles para el análisis de valores
stock_data_df <- as.data.frame(stock_data) %>%
  rownames_to_column(var = "Date") %>%
  mutate(Date = ymd(Date))

# Convertir a tibble y agregar columnas útiles para el análisis de retornos
returns_df <- as.data.frame(returns) %>%
  rownames_to_column(var = "Date") %>%
  mutate(Date = ymd(Date))

```

Un rápido vistazo a los datos:

```{r}

print(summary(stock_data_df[-1][0:9]))

stock_data_df

```

```{r}

print(summary(returns_df[-1][0:9]))

returns_df

```

## Correlaciones

Para mostrar el valor de la técnica Graphical LASSO, en este caso de uso, vamos a aplicar un análisis de correlación de los valores.

Tomando solo 30 stocks stocks al azar:

```{r}

# Seleccionar 30 variables al azar de stock_data_df excluyendo la primera columna
set.seed(42) # Fijar semilla para reproducibilidad
random_columns <- sample(names(stock_data_df)[-1], 30)

# Crear un subconjunto del dataframe con las columnas seleccionadas al azar
stock_data_random <- stock_data_df[random_columns]

# Calcular la matriz de correlación con las 30 columnas seleccionadas
cor_matrix_values <- cor(stock_data_random, use = "pairwise.complete.obs")

# Visualizar la matriz de correlación
corrplot::corrplot(cor_matrix_values, method = "color", tl.cex = 0.6, tl.col = "black")

```
OBSERVACIÓN: hay muchos valores altamente correlacionados, tanto negativa como positivamente.

Preparando un filtro para las variables muy correlacionadas (abs > 0.9), para visualizar mejor los datos:

```{r}

# Filtrar símbolos con alta correlación en valores
pos_corr_pairs_values <- which(cor_matrix_values > 0.9 & abs(cor_matrix_values) < 1, arr.ind = TRUE)
neg_corr_pairs_values <- which(cor_matrix_values < -0.9 & abs(cor_matrix_values) < 1, arr.ind = TRUE)

# Asumimos que ya existen las variables pos_corr_pairs_values y neg_corr_pairs_values
# provenientes del código que mostraste.

# Crear un data frame con los pares altamente correlacionados positivamente
pos_pairs <- data.frame(
  Symbol1 = rownames(cor_matrix_values)[pos_corr_pairs_values[, 1]],
  Symbol2 = colnames(cor_matrix_values)[pos_corr_pairs_values[, 2]],
  Correlation = cor_matrix_values[pos_corr_pairs_values]
)

# Crear un data frame con los pares altamente correlacionados negativamente
neg_pairs <- data.frame(
  Symbol1 = rownames(cor_matrix_values)[neg_corr_pairs_values[, 1]],
  Symbol2 = colnames(cor_matrix_values)[neg_corr_pairs_values[, 2]],
  Correlation = cor_matrix_values[neg_corr_pairs_values]
)

# Si deseas, puedes ver una muestra de estos data frames:
head(pos_pairs)
head(neg_pairs)
```

Entre los pares áltamente correlacionados, podemos comparar a META (comunicación y tecnología) vs. LIN (materiales químicos). Con una correlación positiva de 92.5 %, es muy poco probable que el crecimiento de una impacte directamente en el crecimiento de la otra.

Por otra parte, podemos comparar a HUM (salud) vs. AXP (finanzas), con una correlación negativa de 90.1 %. En este caso, también resulta poco probable que la caída de una impacte directamente en la caída de la otra.

Filtrando dataframes para un EDA:

```{r}

# Columnas con correlacion altamente positiva
pos_corr_stocks <- stock_data_df %>% select(Date, META, LIN)

# Columnas con correlacion altamente positiva
neg_corr_stocks <- stock_data_df %>% select(Date, HUM, NFLX)

stock_data_df

```


## Exploratory Data Analysis (EDA)

1. Tendencia de los precios de cierre para cada símbolo

Correlación positiva:

```{r}
price_trend_plot_filtered <- pos_corr_stocks %>%
  pivot_longer(-Date, names_to = "Symbol", values_to = "Close") %>%
  ggplot(aes(x = Date, y = Close, color = Symbol)) +
  geom_line() +
  labs(title = "Algunas tendencia de precios de cierre", x = "Fecha", y = "Precio de Cierre") +
  theme_minimal()

print(price_trend_plot_filtered)

```

Correlación negativa:

```{r}

price_trend_plot_filtered <- neg_corr_stocks %>%
  pivot_longer(-Date, names_to = "Symbol", values_to = "Close") %>%
  ggplot(aes(x = Date, y = Close, color = Symbol)) +
  geom_line() +
  labs(title = "Algunas tendencia de precios de cierre", x = "Fecha", y = "Precio de Cierre") +
  theme_minimal()

print(price_trend_plot_filtered)

```

2. Histograma de los retornos diarios para cada símbolo filtrado

Correlación positiva:

```{r}

return_hist_plot_filtered <- pos_corr_stocks %>%
  pivot_longer(-Date, names_to = "Symbol", values_to = "Return") %>%
  ggplot(aes(x = Return, fill = Symbol)) +
  geom_histogram(bins = 50, color = "black", alpha = 0.7) +
  labs(title = "Histograma de sus retornos diarios", x = "Retorno diario", y = "Frecuencia") +
  theme_minimal()

print(return_hist_plot_filtered)

```

Correlación negativa:

```{r}

return_hist_plot_filtered <- neg_corr_stocks %>%
  pivot_longer(-Date, names_to = "Symbol", values_to = "Return") %>%
  ggplot(aes(x = Return, fill = Symbol)) +
  geom_histogram(bins = 50, color = "black", alpha = 0.7) +
  labs(title = "Histograma de sus retornos diarios", x = "Retorno diario", y = "Frecuencia") +
  theme_minimal()

print(return_hist_plot_filtered)

```

CONCLUSION: Analizar valores bursátiles/stocks e intentar relacionarlos por sus correlaciones o sus distribuciones de ROC es confuso, sobretodo para el ojo inexperto. Conocer el tipo de industria o negocio que sustenta al stock para relevante, pero aún así no parece suficiente para agruparlos por su compartamiento bursatil.

## Graphical LASSO

Aplicación de la técnica, paso por paso, partiendo del dataframe de retornos en lugar de los valores de cierre. Esto, resulta ventajoso para: 

- Eliminar las tendencias de largo plazo
- Sumar comparabilidad (retornos adimencionales)
- Captar mejor los fenómenos estacionarios
- Reducir impacto de eventos corporativos (splits o distribución de dividendos)
- Foco en las ganancias de los activos, con mayor valor en el mundo del trading

### Cálculo de la Matriz de Covarianza

```{r}

# con returns el método falla y no encuentra relaciones
# cov_matrix <- cov(na.omit(returns)) # al omitir na se pierden varios años de datos VER

cov_matrix <- cov(na.omit(stock_data))

```

### Aplicación de Graphical LASSO

Graphical LASSO estima una **matriz de precisión esparsa** (\( \Omega \)), que es la inversa de la matriz de covarianza regularizada. La matriz de precisión es clave porque cada elemento \( \Omega_{jk} \) describe la **dependencia condicional** entre dos variables (\( X_j \) y \( X_k \)), es decir, cuánto están relacionadas cuando se eliminan los efectos de todas las demás variables.

**Regularización en el Graphical LASSO**

El algoritmo de Graphical LASSO resuelve el siguiente problema de optimización:

\[
\hat{\Omega} = \underset{\Omega \succ 0}{\arg \min} \ \Big[ \text{tr}(\Sigma \Omega) - \log\det(\Omega) + \lambda \|\Omega\|_1 \Big]
\]

Donde:
- \( \Sigma \): matriz de covarianza empírica.
- \( \Omega \): matriz de precisión (inversa de la covarianza).
- \( \text{tr}(\Sigma \Omega) \): traza del producto entre \( \Sigma \) y \( \Omega \).
- \( \log\det(\Omega) \): logaritmo del determinante de \( \Omega \), que garantiza que \( \Omega \) sea positiva definida.
- \( \|\Omega\|_1 \): suma de los valores absolutos de los elementos de \( \Omega \), que induce esparsidad.
- \( \lambda \): parámetro de regularización (también llamado \( \rho \) en algunos contextos).

**Intuición del término de regularización**

A medida que \( \lambda \) aumenta, más elementos de \( \Omega \) se fuerzan a cero, eliminando conexiones entre variables y generando un grafo más esparso. Un \( \lambda \) bajo permite conexiones más débiles y genera un grafo más denso.

#### Matriz de precisión

Usamos la función `glasso` para resolver este problema. El resultado incluye la matriz de precisión regularizada (\( \hat{\Omega} \)):

```{r}

rho <- 0.5  # Valor de regularización
glasso_result <- glasso(cov_matrix, rho = rho)

# Matriz de precisión
precision_matrix <- glasso_result$wi

```

#### Matriz de correlación parcial

La correlación parcial mide la relación directa entre dos variables \( X_j \) y \( X_k \), eliminando los efectos de todas las demás variables (\( X_{\setminus\{j,k\}} \)). Se calcula a partir de la matriz de precisión regularizada (\( \Omega \)).

Dado que \( \Omega \) es la matriz de precisión, la correlación parcial entre \( X_j \) y \( X_k \) está dada por:

\[
R_{jk} = -\frac{\Omega_{jk}}{\sqrt{\Omega_{jj} \cdot \Omega_{kk}}}
\]

Donde:
- \( \Omega_{jk} \): elemento de la matriz de precisión que representa la dependencia condicional entre \( X_j \) y \( X_k \).
- \( \Omega_{jj} \) y \( \Omega_{kk} \): elementos diagonales de \( \Omega \), que representan la varianza condicional de \( X_j \) y \( X_k \).

**Intuición matemática**

Si \( \Omega_{jk} \) es cero, \( R_{jk} = 0 \). Esto indica que \( X_j \) y \( X_k \) son condicionalmente independientes, dado el resto de las variables. Si \( \Omega_{jk} \neq 0 \), el signo y la magnitud de \( R_{jk} \) determinan la dirección y fuerza de la relación directa entre \( X_j \) y \( X_k \).


```{r}

# Calcular matriz de correlación parcial
partial_corr_matrix <- matrix(0, nrow = nrow(precision_matrix), ncol = ncol(precision_matrix))
for (j in 1:nrow(precision_matrix)) {
  for (k in 1:ncol(precision_matrix)) {
    partial_corr_matrix[j, k] <- -precision_matrix[j, k] / sqrt(precision_matrix[j, j] * precision_matrix[k, k])
  }
}
diag(partial_corr_matrix) <- 0  # Evitar autoconexiones
colnames(partial_corr_matrix) <- colnames(returns)
rownames(partial_corr_matrix) <- colnames(returns)

print(partial_corr_matrix)

partial_corr_matrix > 0.1

```

### Visualizar las relaciones como un gráfico de red

Usamos igraph para construir y visualizar un gráfico basado en las conexiones significativas en la matriz de correlación parcial.

```{r}

# Construir grafo desde la matriz de correlación parcial
stock_graph <- graph_from_adjacency_matrix(partial_corr_matrix > 0.1, mode = "undirected", weighted = TRUE)

# Eliminar nodos sin conexiones
isolated <- which(degree(stock_graph) == 0)
stock_graph <- delete_vertices(stock_graph, isolated)

# Asignar colores a los nodos
num_vertices <- vcount(stock_graph)  # Número de nodos en el grafo
palette <- colorRampPalette(RColorBrewer::brewer.pal(12, "Set3"))(num_vertices)
#palette <- RColorBrewer::brewer.pal(min(num_vertices, 12), name = "Set3")  # Asegurar no exceder el límite de 12 colores
V(stock_graph)$color <- palette[1:num_vertices]  # Asignar colores a los nodos

# Visualizar el grafo
plot(stock_graph, vertex.size = 10, vertex.label.cex = 0.8, edge.width = E(stock_graph)$weight * 2)

```

```{r}



```

```{r}



```

```{r}



```

